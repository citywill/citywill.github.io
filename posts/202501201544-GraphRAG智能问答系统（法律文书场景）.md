---
excerpt: null
image: ../assets/202501201544-GraphRAG智能问答系统-对话及知识图谱.png
title: GraphRAG智能问答系统（法律文书场景）
datetime: '2025-01-20 15:44'
permalink: /posts/202501201544
category: 永久笔记
tags:
  - 产品
  - AI
  - RAG
prev:
  text: 50美元超越O1？李飞飞团队S1模型的真相与启示
  link: /posts/202502091322
next:
  text: ObsiGen：Obsidian历史笔记自动生成Agent
  link: /posts/202501121829
---
# GraphRAG智能问答系统（法律文书场景）

这是一款基于图数据库和向量检索的智能问答系统，支持文档管理和智能对话功能。系统使用Neo4j作为图数据库，Streamlit作为前端框架，结合大语言模型实现基于知识图谱的智能问答。

## 功能特点

### 文档管理

- **文档上传**：支持上传txt、md格式的文本文档
- **文档分块**：自定义分隔符和块大小，智能分割文档
- **文档检索**：按标题搜索文档，支持分页查看
- **文档操作**：查看、下载和删除文档
- **元数据查看**：显示文档标题、上传时间、大小、摘要等信息

### 智能对话

- **基于图谱的问答**：结合文档内容和知识图谱，提供智能问答功能
- **知识图谱可视化**：可视化展示与问题相关的知识图谱，支持放大、缩小、拖拽等交互操作
- **实体识别**：自动从文档中提取实体，构建知识图谱
- **向量检索**：使用BGE M3向量模型进行高效语义检索

## 技术栈

- **开发语言**：Python 3.10
- **前端框架**：Streamlit
- **智能体框架**：LangChain
- **数据库**：Neo4j 5.27.0
- **大模型调用**：兼容OpenAI的API接口
- **向量模型**：BGE M3，基于Ollama的API

## 运行方法

### 1. 环境准备

确保安装了Python 3.10，并启动了Neo4j数据库和Ollama服务。

### 2. 安装依赖

```bash
pip install -r requirements.txt
```

### 3. 配置环境变量

编辑`.env`文件，设置以下配置：
- Neo4j数据库连接信息
- 大模型API密钥和基础URL
- 向量模型配置

### 4. 启动应用

```bash
streamlit run app.py
```

### 5. 访问应用

打开浏览器访问：http://localhost:8501

## 使用流程

1. **文档管理**：
   - 上传文档：选择txt或md格式的文件，设置分块参数，点击上传
   - 查看文档：在文档列表中查看已上传的文档信息和内容
   - 下载/删除：对已上传的文档进行下载或删除操作

2. **智能对话**：
   - 输入问题：在对话框中输入要咨询的问题
   - 获取回答：系统自动检索相关文档块并生成回答
   - 查看知识图谱：如果问题与知识图谱相关，可以查看并交互式操作知识图谱

## 注意事项

- 首次使用前需要先上传一些文档，以便系统可以回答相关问题
- 确保Neo4j数据库和Ollama服务正常运行
- 大文件处理可能需要较长时间，请耐心等待
- 实体识别和知识图谱构建基于大模型，效果受模型质量影响


## 产品截图

### 基于知识图谱的问答

![](../assets/202501201544-GraphRAG智能问答系统-对话及知识图谱.png)

### 文档管理

![](../assets/202501201544-GraphRAG智能问答系统-文档管理.png)
